{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the start of your adventure in Agentic AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Are you ready for action??</h2>\n",
    "            <span style=\"color:#ff7800;\">Have you completed all the setup steps in the <a href=\"../setup/\">setup</a> folder?<br/>\n",
    "            Have you read the <a href=\"../README.md\">README</a>? Many common questions are answered here!<br/>\n",
    "            Have you checked out the guides in the <a href=\"../guides/01_intro.ipynb\">guides</a> folder?<br/>\n",
    "            Well in that case, you're ready!!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">This code is a live resource - keep an eye out for my updates</h2>\n",
    "            <span style=\"color:#00bfff;\">I push updates regularly. As people ask questions or have problems, I add more examples and improve explanations. As a result, the code below might not be identical to the videos, as I've added more steps and better comments. Consider this like an interactive book that accompanies the lectures.<br/><br/>\n",
    "            I try to send emails regularly with important updates related to the course. You can find this in the 'Announcements' section of Udemy in the left sidebar. You can also choose to receive my emails via your Notification Settings in Udemy. I'm respectful of your inbox and always try to add value with my emails!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And please do remember to contact me if I can help\n",
    "\n",
    "And I love to connect: https://www.linkedin.com/in/eddonner/\n",
    "\n",
    "\n",
    "### New to Notebooks like this one? Head over to the guides folder!\n",
    "\n",
    "Just to check you've already added the Python and Jupyter extensions to Cursor, if not already installed:\n",
    "- Open extensions (View >> extensions)\n",
    "- Search for python, and when the results show, click on the ms-python one, and Install it if not already installed\n",
    "- Search for jupyter, and when the results show, click on the Microsoft one, and Install it if not already installed  \n",
    "Then View >> Explorer to bring back the File Explorer.\n",
    "\n",
    "And then:\n",
    "1. Click where it says \"Select Kernel\" near the top right, and select the option called `.venv (Python 3.12.9)` or similar, which should be the first choice or the most prominent choice. You may need to choose \"Python Environments\" first.\n",
    "2. Click in each \"cell\" below, starting with the cell immediately below this text, and press Shift+Enter to run\n",
    "3. Enjoy!\n",
    "\n",
    "After you click \"Select Kernel\", if there is no option like `.venv (Python 3.12.9)` then please do the following:  \n",
    "1. On Mac: From the Cursor menu, choose Settings >> VS Code Settings (NOTE: be sure to select `VSCode Settings` not `Cursor Settings`);  \n",
    "On Windows PC: From the File menu, choose Preferences >> VS Code Settings(NOTE: be sure to select `VSCode Settings` not `Cursor Settings`)  \n",
    "2. In the Settings search bar, type \"venv\"  \n",
    "3. In the field \"Path to folder with a list of Virtual Environments\" put the path to the project root, like C:\\Users\\username\\projects\\agents (on a Windows PC) or /Users/username/projects/agents (on Mac or Linux).  \n",
    "And then try again.\n",
    "\n",
    "Having problems with missing Python versions in that list? Have you ever used Anaconda before? It might be interferring. Quit Cursor, bring up a new command line, and make sure that your Anaconda environment is deactivated:    \n",
    "`conda deactivate`  \n",
    "And if you still have any problems with conda and python versions, it's possible that you will need to run this too:  \n",
    "`conda config --set auto_activate_base false`  \n",
    "and then from within the Agents directory, you should be able to run `uv python list` and see the Python 3.12 version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dotenv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# First let's do an import. If you get an Import Error, double check that your Kernel is correct..\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'dotenv'"
     ]
    }
   ],
   "source": [
    "# First let's do an import. If you get an Import Error, double check that your Kernel is correct..\n",
    "\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next it's time to load the API keys into environment variables\n",
    "# If this returns false, see the next cell!\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait, did that just output `False`??\n",
    "\n",
    "If so, the most common reason is that you didn't save your `.env` file after adding the key! Be sure to have saved.\n",
    "\n",
    "Also, make sure the `.env` file is named precisely `.env` and is in the project root directory (`agents`)\n",
    "\n",
    "By the way, your `.env` file should have a stop symbol next to it in Cursor on the left, and that's actually a good thing: that's Cursor saying to you, \"hey, I realize this is a file filled with secret information, and I'm not going to send it to an external AI to suggest changes, because your keys should not be shown to anyone else.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Final reminders</h2>\n",
    "            <span style=\"color:#ff7800;\">1. If you're not confident about Environment Variables or Web Endpoints / APIs, please read Topics 3 and 5 in this <a href=\"../guides/04_technical_foundations.ipynb\">technical foundations guide</a>.<br/>\n",
    "            2. If you want to use AIs other than OpenAI, like Gemini, DeepSeek or Ollama (free), please see the first section in this <a href=\"../guides/09_ai_apis_and_ollama.ipynb\">AI APIs guide</a>.<br/>\n",
    "            3. If you ever get a Name Error in Python, you can always fix it immediately; see the last section of this <a href=\"../guides/06_python_foundations.ipynb\">Python Foundations guide</a> and follow both tutorials and exercises.<br/>\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the key - if you're not using OpenAI, check whichever key you're using! Ollama doesn't need a key.\n",
    "\n",
    "import os\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set - please head to the troubleshooting guide in the setup folder\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now - the all important import statement\n",
    "# If you get an import error - head over to troubleshooting in the Setup folder\n",
    "# Even for other LLM providers like Gemini, you still use this OpenAI import - see Guide 9 for why\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now we'll create an instance of the OpenAI class\n",
    "# If you're not sure what it means to create an instance of a class - head over to the guides folder (guide 6)!\n",
    "# If you get a NameError - head over to the guides folder (guide 6)to learn about NameErrors - always instantly fixable\n",
    "# If you're not using OpenAI, you just need to slightly modify this - precise instructions are in the AI APIs guide (guide 9)\n",
    "\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of messages in the familiar OpenAI format\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"What is 2+2?\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now call it! Any problems, head to the troubleshooting guide\n",
    "# This uses GPT 4.1 nano, the incredibly cheap model\n",
    "# The APIs guide (guide 9) has exact instructions for using even cheaper or free alternatives to OpenAI\n",
    "# If you get a NameError, head to the guides folder (guide 6) to learn about NameErrors - always instantly fixable\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now - let's ask for a question:\n",
    "\n",
    "question = \"Please propose a hard, challenging question to assess someone's IQ. Respond only with the question.\"\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ask it - this uses GPT 4.1 mini, still cheap but more powerful than nano\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "question = response.choices[0].message.content\n",
    "\n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# form a new messages list\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask it again\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "answer = response.choices[0].message.content\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(answer))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulationssssss!\n",
    "\n",
    "That was a small, simple step in the direction of Agentic AI, with your new environment!\n",
    "\n",
    "Next time things get more interesting..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercissssseeeee</h2>\n",
    "            <span style=\"color:#ff7800;\">Now try this commercial application:<br/>\n",
    "            First ask the LLM to pick a business area that might be worth exploring for an Agentic AI opportunity.<br/>\n",
    "            Then ask the LLM to present a pain-point in that industry - something challenging that might be ripe for an Agentic solution.<br/>\n",
    "            Finally have 3 third LLM call propose the Agentic AI solution. <br/>\n",
    "            We will cover this at up-coming labs, so don't worry if you're unsure.. just give it a try!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling dde5aa3fc5ff: 100% ▕██████████████████▏ 2.0 GB                         \u001b[K\n",
      "pulling 966de95ca8a6: 100% ▕██████████████████▏ 1.4 KB                         \u001b[K\n",
      "pulling fcc5a6bec9da: 100% ▕██████████████████▏ 7.7 KB                         \u001b[K\n",
      "pulling a70ff7e570d9: 100% ▕██████████████████▏ 6.0 KB                         \u001b[K\n",
      "pulling 56bb8bd477a5: 100% ▕██████████████████▏   96 B                         \u001b[K\n",
      "pulling 34bb5ab01051: 100% ▕██████████████████▏  561 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
    "ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key=\"anything\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"pick a business area and pick an industry which could be worth exploring for AI Industry\"\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd like to explore the industry of Healthcare Technology (Health Tech) as a potential field for applying AI. With the rapid advancement in healthcare technology, there is a growing need for innovative solutions that can improve patient outcomes, reduce costs, and enhance the overall patient experience.\n",
      "\n",
      "Industry: HealthTech\n",
      "\n",
      "Description:\n",
      "HealthTech encompasses a wide range of technologies and services aimed at improving healthcare delivery, from medical devices and wearables to digital health platforms and AI-powered diagnostics. The industry has shown tremendous growth in recent years, driven by the increasing demand for innovative solutions that can address pressing healthcare challenges.\n",
      "\n",
      "AI applications in HealthTech:\n",
      "\n",
      "1. **Medical Imaging Analysis**: AI can be used to analyze medical images such as X-rays, CT scans, and MRIs to help doctors diagnose diseases more accurately.\n",
      "2. **Predictive Analytics**: AI-powered algorithms can analyze large amounts of patient data to predict disease progression, identify high-risk patients, and prevent hospital readmissions.\n",
      "3. **Natural Language Processing (NLP)**: NLP can be used to extract relevant information from electronic health records (EHRs) and provide insights for clinicians to improve patient care.\n",
      "4. **Robot-Assisted Surgery**: AI-powered robots can assist surgeons during complex procedures, improving precision and reducing recovery time.\n",
      "5. **Chatbots and Virtual Assistants**: Chatbots and virtual assistants can be integrated into healthcare systems to help patients manage their conditions, schedule appointments, and provide personalized support.\n",
      "\n",
      "Potential businesses in HealthTech:\n",
      "\n",
      "1. **Medical Imaging Analysis Software**: Develop software that uses AI to analyze medical images and provide diagnostic insights.\n",
      "2. **Healthcare Data Analytics Platforms**: Create platforms that use predictive analytics and machine learning to analyze healthcare data and provide actionable insights for clinicians and patients.\n",
      "3. **Wearable Devices and Wearables Analytics**: Develop wearables that track vital signs, activity levels, and other health metrics, providing valuable data for personalization of care.\n",
      "4. **Virtual Reality Therapy**: Create virtual reality experiences that use AI-powered avatars to help patients overcome phobias, anxiety disorders, or PTSD.\n",
      "\n",
      "These are just a few examples of the many exciting business opportunities in HealthTech where AI can be applied to improve healthcare outcomes, enhance patient experiences, and reduce costs.\n"
     ]
    }
   ],
   "source": [
    "response = ollama.chat.completions.create(\n",
    "    model = \"llama3.2\",\n",
    "    messages = messages\n",
    ")\n",
    "answer = response.choices[0].message.content\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's explore the business area of Healthcare and within the industry, we can focus on Medical Imaging Analysis. This is a highly relevant and growing market that combines Artificial Intelligence (AI), Computer Vision, and Machine Learning to extract insights from medical images such as X-rays, CT scans, MRIs, and more.\n",
      "\n",
      "**Industry Background:**\n",
      "\n",
      "Medical imaging analysis involves the use of AI algorithms to process and analyze medical images for diagnosis, treatment planning, and research purposes. This industry has seen rapid growth in recent years, driven by advancements in technology and the increasing demand for high-quality healthcare services.\n",
      "\n",
      "**AI Applications:**\n",
      "\n",
      "Some examples of AI applications in Medical Imaging Analysis include:\n",
      "\n",
      "1. **Cancer Detection and Diagnosis**: AI algorithms can analyze medical images to detect cancerous tissue, identify tumors, and help doctors diagnose the type and stage of cancer.\n",
      "2. **Automated Segmentation**: AI can automate the process of extracting specific regions from medical images, such as organs or tumors, which helps with diagnosis and treatment planning.\n",
      "3. **Image Analysis for Other Conditions**: AI can also be used to analyze medical images for other conditions, such as diabetic retinopathy, cardiovascular disease, and musculoskeletal disorders.\n",
      "\n",
      "**Benefits:**\n",
      "\n",
      "The use of AI in Medical Imaging Analysis offers several benefits, including:\n",
      "\n",
      "1. **Improved Accuracy**: AI algorithms can process large amounts of data quickly and accurately, reducing the reliance on human interpretation.\n",
      "2. **Increased Efficiency**: AI can automate many tasks, freeing up healthcare professionals to focus on more complex cases.\n",
      "3. **Enhanced Patient Care**: AI-driven insights from medical images can help doctors make more informed decisions about patient care.\n",
      "\n",
      "**Potential Revenue Streams:**\n",
      "\n",
      "1. **Image Analysis Software**: Developing and selling software that provides AI-powered image analysis capabilities for healthcare professionals.\n",
      "2. **Subscription-based Services**: Offering subscription-based services that provide access to AI-trained models and expertise for ongoing image analysis tasks.\n",
      "3. **Data Analytics**: Providing data analytics services to help healthcare organizations understand their medical image data, identify trends, and make data-driven decisions.\n",
      "\n",
      "**Challenges:**\n",
      "\n",
      "1. **Regulatory Compliance**: Ensuring compliance with regulations such as HIPAA (Health Insurance Portability and Accountability Act) and FDA guidelines for medical imaging software.\n",
      "2. **Data Quality**: Managing the quality of medical images, including issues related to image resolution, quality, and storage.\n",
      "3. **Cybersecurity**: Protecting sensitive medical data from cyber threats.\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "The Medical Imaging Analysis industry is a rapidly growing market with numerous AI applications that can transform healthcare services. While there are challenges associated with regulatory compliance, data quality, and cybersecurity, the benefits of using AI in this industry far outweigh the risks. By developing intelligent image analysis software and providing expert analytics services, those interested in exploring this space may find opportunities to innovate and create value in this exciting area.\n"
     ]
    }
   ],
   "source": [
    "question = \"pick a business area and pick an industry which could be worth exploring for AI Industry\"\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n",
    "response = ollama.chat.completions.create(\n",
    "    model = \"llama3.2\",\n",
    "    messages = messages\n",
    ")\n",
    "answer = response.choices[0].message.content\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Industry: E-learning and Online Education\n",
      "\n",
      "Pain-Point:\n",
      "\n",
      "**Scaling Access to Quality Education while Managing Costs**\n",
      "\n",
      "The online education sector faces a significant challenge in providing accessible, high-quality learning experiences to students worldwide while keeping costs manageable. The traditional model of delivering courses through traditional brick-and-mortar institutions or expensive digital platforms has limitations.\n",
      "\n",
      "Specifically:\n",
      "\n",
      "* **Limited resources**: Many organizations and governments struggle to allocate sufficient funds for creating engaging, effective online content that meets the needs of diverse learners.\n",
      "* **Outdated curriculum standards**: Existing curricula often fail to keep pace with rapidly changing technologies, making it challenging to maintain relevance and accuracy.\n",
      "* **Scalability issues**: As demand grows, institutions face difficulties in scaling their infrastructure to support large numbers of students, leading to:\n",
      " + Insufficient instructional capacity\n",
      " + Limited assessment tools\n",
      " + Inadequate student support services\n",
      "\n",
      "Agentic Solution:\n",
      "\n",
      "**AI-Powered Personalized Learning Platforms for Scalable Edutainment**\n",
      "\n",
      "Develop an adaptive learning platform that leverages artificial intelligence (AI) and machine learning algorithms to offer personalized learning experiences tailored to individual students' needs. This platform would utilize natural language processing, computer vision, and data analytics to:\n",
      "\n",
      "1. **Automate content creation**: Generate personalized course materials based on a learner's goals, pace, and preferences.\n",
      "2. **Optimize assessment tools**: Develop intelligent assessments that adjust in difficulty and type according to the student's performance.\n",
      "3. **Enhance accessibility**: Incorporate multilingual support, color blindness compensation, and speech-to-text functionality.\n",
      "\n",
      "Goals:\n",
      "\n",
      "* Increase access to quality education for underrepresented groups (e.g., low-income students, people with disabilities)\n",
      "* Reduce costs associated with traditional content development and delivery methods\n",
      "* Improve student engagement, retention rates, and overall learning outcomes\n",
      "\n",
      "Key Benefits:\n",
      "\n",
      "* **Scalability**: Offer high-quality education to a large number of students while maintaining affordability.\n",
      "* **Personalization**: Adaptive learning experiences tailored to individual learners' needs.\n",
      "* **Efficiency**: Reduced development and delivery costs.\n",
      "\n",
      "This solution addresses the industry pain-point by providing an innovative way to deliver more accessible, effective, and efficient online education.\n"
     ]
    }
   ],
   "source": [
    "question = \"present a pain-point in that industry - something challenging that might be ripe for an Agentic solution.\"\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n",
    "response = ollama.chat.completions.create(\n",
    "    model = \"llama3.2\",\n",
    "    messages = messages\n",
    ")\n",
    "answer2 = response.choices[0].message.content\n",
    "print(answer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"pick a business area and pick an industry which could be worth exploring for AI Industry\"\n",
    "messages = [{\"role\": \"user\", \"content\": question}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's explore the business area of \"Healthcare\" and specific industries that could benefit from AI.\n",
      "\n",
      "**Industry:** **Medical Imaging Analysis**\n",
      "\n",
      "Medical imaging analysis is a rapidly growing field within healthcare, leveraging AI and machine learning to enhance image interpretation, diagnose diseases more accurately, and reduce healthcare costs. The industry involves analyzing medical images such as X-rays, CT scans, MRI scans, and ultrasounds using AI algorithms to detect abnormalities, identify potential health threats, and develop personalized treatment plans.\n",
      "\n",
      "**Why this industry is promising for AI:**\n",
      "\n",
      "1. **High-volume datasets**: Medical imaging analysis generates vast amounts of data, providing a rich source of material for training and fine-tuning AI models.\n",
      "2. **Complex decision-making**: Radiologists spend countless hours interpreting images to diagnose conditions that are often subtle or hard to spot with the naked eye, making AI a valuable tool in this process.\n",
      "3. **Potential benefits across multiple areas**: Applying AI to medical imaging analysis could improve patient outcomes, reduce healthcare costs, and enhance data-driven research opportunities.\n",
      "\n",
      "Some potential applications of AI in medical imaging analysis include:\n",
      "\n",
      "-  Automated tumor detection and tracking\n",
      "- Disease diagnosis from minimal or abnormal test results\n",
      "- Enhanced monitoring for specific diseases\n",
      "\n",
      "With AI developing rapidly across various industries, focusing on this area presents significant growth opportunity.\n",
      "\n",
      "Would you like me to elaborate more?\n"
     ]
    }
   ],
   "source": [
    "response = ollama.chat.completions.create(\n",
    "    model = \"llama3.2\",\n",
    "    messages = messages\n",
    ")\n",
    "question = response.choices[0].message.content\n",
    "print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's one:\n",
      "\n",
      "There are three switches, but they are not labelled. Each switch corresponds to one of three light bulbs in a room. Each light bulb is either on or off. You can turn the switches on and off as many times as you want, but you can only enter the room once to observe the light bulbs. How can you figure out which switch corresponds to which light bulb?\n",
      "\n",
      "Think you can solve it?\n"
     ]
    }
   ],
   "source": [
    "question = \"give me a brain teaser riddle\"\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n",
    "response = ollama.chat.completions.create(\n",
    "    model = \"llama3.2\",\n",
    "    messages = messages\n",
    ")\n",
    "question = response.choices[0].message.content\n",
    "print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This classic puzzle is indeed solvable with a few clever steps.\n",
      "\n",
      "Here's one way to solve it:\n",
      "\n",
      "1. Turn switch 1 to ON for 5 minutes.\n",
      "2. Turn off switch 1 and turn on switch 2.\n",
      "3. Immediately enter the room.\n",
      "\n",
      "Now, observe the light bulbs:\n",
      "\n",
      "- The bulb that is **on** corresponds to switch 2.\n",
      "- The bulb that is **off**, but **warm** (or has a little heat) corresponds to switch 1. This is because the bulb was recently turned off and still retains some residual heat from being heated by switch 1.\n",
      "- The bulb that is **off**, and **cold** (or is completely dark and cold to the touch), corresponds to switch 3.\n",
      "\n",
      "To solve it, we need to make use of the fact that an incandescent bulb (the most common type) retains Heat for about 10-15 minutes after being turned off. This means that as soon as you turn a light on or off, there will be a certain delay before the corresponding bulb has time to cool down.\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": question}]\n",
    "response = ollama.chat.completions.create(\n",
    "    model = \"llama3.2\",\n",
    "    messages = messages\n",
    ")\n",
    "answer = response.choices[0].message.content\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1d9bd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dotenv\n",
      "  Downloading dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\n",
      "Collecting python-dotenv (from dotenv)\n",
      "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Downloading dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\n",
      "Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Installing collected packages: python-dotenv, dotenv\n",
      "\n",
      "   ---------------------------------------- 0/2 [python-dotenv]\n",
      "   -------------------- ------------------- 1/2 [dotenv]\n",
      "   ---------------------------------------- 2/2 [dotenv]\n",
      "\n",
      "Successfully installed dotenv-0.9.9 python-dotenv-1.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3fa1b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4590e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1dc5186",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_api_key = os.getenv('GOOGLE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62250881",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2a938a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = \"Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. \"\n",
    "request += \"Answer only with the question, no explanation.\"\n",
    "messages = [{\"role\": \"user\", \"content\": request}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a482adaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': 'Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. Answer only with the question, no explanation.'}]\n"
     ]
    }
   ],
   "source": [
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5224dfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini = OpenAI(api_key=\"AIzaSyDBkeFUTaBoKFUUuB5tkA4cFAOxsmX4EFo\", base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
    "model_name = \"gemini-2.5-flash\"\n",
    "\n",
    "response = gemini.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6ae8529",
   "metadata": {},
   "outputs": [],
   "source": [
    "competitors = []\n",
    "answers = []\n",
    "messages = [{\"role\": \"user\", \"content\": answer}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d662eba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The concept of \"truth\" in modern information ecosystems is fraught with tension. If you were tasked with designing an idealized digital public sphere, would its primary objective be to maximize the propagation of verifiable facts, to foster diverse interpretative frameworks, or to cultivate resilient critical thinking skills in its users? Argue for your chosen primary objective, acknowledging the inherent trade-offs and potential harms of prioritizing it over the others, and explain how its success would be measured in a complex, self-organizing system."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d875e860",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling dde5aa3fc5ff: 100% ▕██████████████████▏ 2.0 GB                         \u001b[K\n",
      "pulling 966de95ca8a6: 100% ▕██████████████████▏ 1.4 KB                         \u001b[K\n",
      "pulling fcc5a6bec9da: 100% ▕██████████████████▏ 7.7 KB                         \u001b[K\n",
      "pulling a70ff7e570d9: 100% ▕██████████████████▏ 6.0 KB                         \u001b[K\n",
      "pulling 56bb8bd477a5: 100% ▕██████████████████▏   96 B                         \u001b[K\n",
      "pulling 34bb5ab01051: 100% ▕██████████████████▏  561 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "53a91fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = \"Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. \"\n",
    "request += \"Answer only with the question, no explanation.\"\n",
    "messages = [{\"role\": \"user\", \"content\": request}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c01b3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "model_name = \"llama3.2\"\n",
    "\n",
    "response = ollama.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f0d287c",
   "metadata": {},
   "outputs": [],
   "source": [
    "competitors = []\n",
    "answers = []\n",
    "messages = [{\"role\": \"user\", \"content\": answer}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4959b9ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "What is the most probable sequence of historical events leading to the fall of the Ottoman Empire, considering the complex interplay between internal power struggles, external pressures, and socio-economic factors in 20th century Turkey?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5bdeb724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gemini-2.5-flash', 'llama3.2', 'llama3.2']\n",
      "['The concept of \"truth\" in modern information ecosystems is fraught with tension. If you were tasked with designing an idealized digital public sphere, would its primary objective be to maximize the propagation of verifiable facts, to foster diverse interpretative frameworks, or to cultivate resilient critical thinking skills in its users? Argue for your chosen primary objective, acknowledging the inherent trade-offs and potential harms of prioritizing it over the others, and explain how its success would be measured in a complex, self-organizing system.', 'What is the most probable sequence of historical events leading to the fall of the Ottoman Empire, considering the complex interplay between internal power struggles, external pressures, and socio-economic factors in 20th century Turkey?', 'What is the most probable sequence of historical events leading to the fall of the Ottoman Empire, considering the complex interplay between internal power struggles, external pressures, and socio-economic factors in 20th century Turkey?']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(competitors)\n",
    "print(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b27a5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Competitor: gemini-2.5-flash\n",
      "\n",
      "The concept of \"truth\" in modern information ecosystems is fraught with tension. If you were tasked with designing an idealized digital public sphere, would its primary objective be to maximize the propagation of verifiable facts, to foster diverse interpretative frameworks, or to cultivate resilient critical thinking skills in its users? Argue for your chosen primary objective, acknowledging the inherent trade-offs and potential harms of prioritizing it over the others, and explain how its success would be measured in a complex, self-organizing system.\n",
      "Competitor: llama3.2\n",
      "\n",
      "What is the most probable sequence of historical events leading to the fall of the Ottoman Empire, considering the complex interplay between internal power struggles, external pressures, and socio-economic factors in 20th century Turkey?\n",
      "Competitor: llama3.2\n",
      "\n",
      "What is the most probable sequence of historical events leading to the fall of the Ottoman Empire, considering the complex interplay between internal power struggles, external pressures, and socio-economic factors in 20th century Turkey?\n"
     ]
    }
   ],
   "source": [
    "for competitors, answer in zip(competitors, answers):\n",
    "    print(f\"Competitor: {competitors}\\n\\n{answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0e01199",
   "metadata": {},
   "outputs": [],
   "source": [
    "together = \"\"\n",
    "for index, answer in enumerate(answers):\n",
    "    together += f\"# Response from competitor {index+1}\\n\\n\"\n",
    "    together += answer + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c538da87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Response from competitor 1\n",
      "\n",
      "The concept of \"truth\" in modern information ecosystems is fraught with tension. If you were tasked with designing an idealized digital public sphere, would its primary objective be to maximize the propagation of verifiable facts, to foster diverse interpretative frameworks, or to cultivate resilient critical thinking skills in its users? Argue for your chosen primary objective, acknowledging the inherent trade-offs and potential harms of prioritizing it over the others, and explain how its success would be measured in a complex, self-organizing system.\n",
      "\n",
      "# Response from competitor 2\n",
      "\n",
      "What is the most probable sequence of historical events leading to the fall of the Ottoman Empire, considering the complex interplay between internal power struggles, external pressures, and socio-economic factors in 20th century Turkey?\n",
      "\n",
      "# Response from competitor 3\n",
      "\n",
      "What is the most probable sequence of historical events leading to the fall of the Ottoman Empire, considering the complex interplay between internal power struggles, external pressures, and socio-economic factors in 20th century Turkey?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ded0e2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "judge = f\"\"\"You are judging a competition between {len(competitors)} competitors.\n",
    "Each model has been given this question:\n",
    "\n",
    "{answer}\n",
    "\n",
    "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
    "Respond with JSON, and only JSON, with the following format:\n",
    "{{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}}\n",
    "\n",
    "Here are the responses from each competitor:\n",
    "\n",
    "{together}\n",
    "\n",
    "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a8dbf77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are judging a competition between 8 competitors.\n",
      "Each model has been given this question:\n",
      "\n",
      "What is the most probable sequence of historical events leading to the fall of the Ottoman Empire, considering the complex interplay between internal power struggles, external pressures, and socio-economic factors in 20th century Turkey?\n",
      "\n",
      "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
      "Respond with JSON, and only JSON, with the following format:\n",
      "{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}\n",
      "\n",
      "Here are the responses from each competitor:\n",
      "\n",
      "# Response from competitor 1\n",
      "\n",
      "The concept of \"truth\" in modern information ecosystems is fraught with tension. If you were tasked with designing an idealized digital public sphere, would its primary objective be to maximize the propagation of verifiable facts, to foster diverse interpretative frameworks, or to cultivate resilient critical thinking skills in its users? Argue for your chosen primary objective, acknowledging the inherent trade-offs and potential harms of prioritizing it over the others, and explain how its success would be measured in a complex, self-organizing system.\n",
      "\n",
      "# Response from competitor 2\n",
      "\n",
      "What is the most probable sequence of historical events leading to the fall of the Ottoman Empire, considering the complex interplay between internal power struggles, external pressures, and socio-economic factors in 20th century Turkey?\n",
      "\n",
      "# Response from competitor 3\n",
      "\n",
      "What is the most probable sequence of historical events leading to the fall of the Ottoman Empire, considering the complex interplay between internal power struggles, external pressures, and socio-economic factors in 20th century Turkey?\n",
      "\n",
      "\n",
      "\n",
      "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\n"
     ]
    }
   ],
   "source": [
    "print(judge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3332815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_messages = [{\"role\": \"user\", \"content\": judge}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c5a91b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"results\": [\"1\", \"2\", \"3\"]}\n"
     ]
    }
   ],
   "source": [
    "gemini = OpenAI(api_key=\"AIzaSyDBkeFUTaBoKFUUuB5tkA4cFAOxsmX4EFo\", base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
    "model_name = \"gemini-2.5-flash\"\n",
    "\n",
    "response = gemini.chat.completions.create(model=model_name, messages=judge_messages)\n",
    "results = response.choices[0].message.content\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3ae261a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: l\n",
      "Rank 2: l\n",
      "Rank 3: a\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results_dict = json.loads(results)\n",
    "ranks = results_dict[\"results\"]\n",
    "for index, result in enumerate(ranks):\n",
    "    competitor = competitors[int(result)-1]\n",
    "    print(f\"Rank {index+1}: {competitor}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
